# üöÄ H∆Ø·ªöNG D·∫™N T·ªêI ∆ØU H√ìA ADMIN PANEL - IVIE WEDDING STUDIO

## üìã T·ªïng Quan

T√†i li·ªáu n√†y h∆∞·ªõng d·∫´n c√°ch t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t cho Backend v√† Admin Panel c·ªßa IVIE Wedding Studio.

## üéØ M·ª•c Ti√™u T·ªëi ∆Øu

- **Response Time**: Gi·∫£m t·ª´ >2s xu·ªëng <500ms
- **Database Queries**: T·ªëi ∆∞u v·ªõi indexing v√† caching
- **Memory Usage**: Gi·∫£m 30-50% v·ªõi connection pooling
- **Concurrent Users**: H·ªó tr·ª£ nhi·ªÅu admin truy c·∫≠p ƒë·ªìng th·ªùi

---

## üìÅ C·∫•u Tr√∫c Files T·ªëi ∆Øu

```
backend/ung_dung/
‚îú‚îÄ‚îÄ cache_advanced.py          # Advanced caching layer
‚îú‚îÄ‚îÄ cache_utils.py             # Basic cache utilities  
‚îú‚îÄ‚îÄ co_so_du_lieu_optimized.py # Database v·ªõi connection pooling
‚îú‚îÄ‚îÄ chinh_optimized.py         # FastAPI app t·ªëi ∆∞u
‚îî‚îÄ‚îÄ dinh_tuyen/
    ‚îî‚îÄ‚îÄ san_pham_optimized.py  # API endpoints t·ªëi ∆∞u

admin-python/
‚îî‚îÄ‚îÄ quan_tri_optimized.py      # Streamlit admin t·ªëi ∆∞u

optimize_admin.py              # Script monitoring & optimization
```

---

## üîß C√†i ƒê·∫∑t

### 1. C·∫≠p nh·∫≠t Dependencies

```bash
# Backend
cd backend
pip install -r requirements_optimized.txt

# Ho·∫∑c c√†i c√°c package quan tr·ªçng
pip install redis hiredis psutil asyncpg aiofiles
```

### 2. C·∫•u h√¨nh Environment Variables

Th√™m v√†o file `.env`:

```env
# Database
DATABASE_URL=postgresql://user:pass@host:5432/dbname

# Redis Cache (Optional - n·∫øu c√≥)
REDIS_URL=redis://localhost:6379/0

# Performance Settings
DEBUG=false
CORS_ORIGINS=http://localhost:3000,https://your-domain.com
```

### 3. Kh·ªüi ƒë·ªông v·ªõi Optimized Version

```bash
# Thay th·∫ø chinh.py b·∫±ng chinh_optimized.py
# Ho·∫∑c update import trong chinh.py

# Ch·∫°y uvicorn v·ªõi workers
uvicorn ung_dung.chinh:ung_dung --host 0.0.0.0 --port 8000 --workers 4
```

---

## üíæ DATABASE OPTIMIZATION

### Indexes T·ª± ƒê·ªông

File `co_so_du_lieu_optimized.py` t·ª± ƒë·ªông t·∫°o c√°c indexes:

```sql
-- S·∫£n ph·∫©m
CREATE INDEX idx_san_pham_category ON san_pham(category);
CREATE INDEX idx_san_pham_category_gender ON san_pham(category, gender);
CREATE INDEX idx_san_pham_price ON san_pham(rental_price_day);

-- ƒê∆°n h√†ng  
CREATE INDEX idx_don_hang_status ON don_hang(status);
CREATE INDEX idx_don_hang_status_date ON don_hang(status, order_date);

-- ƒê√°nh gi√°
CREATE INDEX idx_danh_gia_product_approved ON danh_gia(product_id, is_approved);
```

### Connection Pooling

```python
from co_so_du_lieu_optimized import get_engine, lay_csdl_optimized

# C·∫•u h√¨nh pool
engine = create_engine(
    url,
    pool_size=5,          # S·ªë connection c∆° b·∫£n
    max_overflow=10,      # Connection th√™m khi c·∫ßn
    pool_timeout=30,      # Timeout khi ƒë·ª£i
    pool_recycle=1800,    # Recycle sau 30 ph√∫t
    pool_pre_ping=True,   # Ki·ªÉm tra tr∆∞·ªõc khi d√πng
)
```

### SQLite Optimization (Development)

```python
# T·ª± ƒë·ªông √°p d·ª•ng PRAGMA
PRAGMA journal_mode=WAL;     # Concurrent reads
PRAGMA cache_size=-64000;    # 64MB cache
PRAGMA synchronous=NORMAL;
PRAGMA temp_store=MEMORY;
PRAGMA mmap_size=268435456;  # 256MB mmap
```

---

## üóÑÔ∏è CACHING STRATEGY

### Cache Layers

1. **Response Cache**: Cache HTTP responses
2. **Query Cache**: Cache database queries
3. **Application Cache**: Cache computed data

### Cache TTL Settings

```python
CACHE_TTL = {
    "INSTANT": 30,      # Real-time data
    "SHORT": 60,        # Frequently changing
    "MEDIUM": 300,      # Product lists (5 ph√∫t)
    "LONG": 900,        # Category data (15 ph√∫t)
    "EXTENDED": 3600,   # Static content (1 gi·ªù)
}
```

### S·ª≠ d·ª•ng Cache

```python
from cache_advanced import cached, redis_client, invalidator

# Decorator caching
@cached("products", ttl=300)
def get_products(category=None):
    return db.query(Product).filter(...).all()

# Manual caching
data = redis_client.get("my_key")
if not data:
    data = expensive_operation()
    redis_client.set("my_key", data, ttl=300)

# Invalidate sau khi update
invalidator.invalidate_products()
```

### Cache Rules (Response)

```python
CACHE_RULES = {
    "/api/san_pham": 300,    # 5 ph√∫t
    "/api/banner": 900,      # 15 ph√∫t
    "/api/thu_vien": 3600,   # 1 gi·ªù
    "/api/thong_ke": 60,     # 1 ph√∫t
}
```

---

## ‚ö° API OPTIMIZATION

### Pagination

```python
# New pagination format
GET /api/san_pham/?page=1&page_size=20

# Response
{
    "items": [...],
    "pagination": {
        "total": 100,
        "page": 1,
        "page_size": 20,
        "total_pages": 5,
        "has_next": true,
        "has_prev": false
    }
}
```

### Bulk Operations

```python
# T·∫°o nhi·ªÅu s·∫£n ph·∫©m
POST /api/san_pham/bulk
Body: [{"name": "SP1", ...}, {"name": "SP2", ...}]

# C·∫≠p nh·∫≠t nhi·ªÅu s·∫£n ph·∫©m
PUT /api/san_pham/bulk
Body: [{"id": 1, "price": 100}, {"id": 2, "price": 200}]

# X√≥a nhi·ªÅu s·∫£n ph·∫©m
DELETE /api/san_pham/bulk
Body: [1, 2, 3, 4, 5]
```

### Quick Toggle

```python
# Toggle hot status
PATCH /api/san_pham/123/toggle-hot

# Toggle new status
PATCH /api/san_pham/123/toggle-new
```

---

## üñ•Ô∏è STREAMLIT ADMIN OPTIMIZATION

### Session State

```python
# Kh·ªüi t·∫°o m·ªôt l·∫ßn
if "products_cache" not in st.session_state:
    st.session_state.products_cache = None

# Cache data trong session
@st.cache_data(ttl=300)
def fetch_products():
    return api_request("/api/san_pham/")
```

### Parallel Requests

```python
from concurrent.futures import ThreadPoolExecutor

# Fetch nhi·ªÅu endpoints c√πng l√∫c
def fetch_parallel(endpoints):
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {executor.submit(fetch, ep): ep for ep in endpoints}
        return {futures[f]: f.result() for f in as_completed(futures)}
```

### Lazy Image Loading

```python
@st.cache_data(ttl=3600)
def get_image_thumbnail(url, size=(100, 100)):
    # Download v√† resize ·∫£nh
    # Cache k·∫øt qu·∫£
    pass
```

### Skeleton Loading

```python
def show_loading_skeleton():
    st.markdown("""
    <style>
    .skeleton {
        background: linear-gradient(90deg, #2a2a2a 25%, #3a3a3a 50%, #2a2a2a 75%);
        animation: shimmer 1.5s infinite;
    }
    </style>
    """, unsafe_allow_html=True)
```

---

## üìä MONITORING & BENCHMARKING

### Health Check

```bash
python optimize_admin.py health-check

# Output
‚úÖ API server: OK (0.123s)
‚úÖ Database: OK (0.045s)
‚úÖ Cache: OK (0.012s)
```

### Performance Benchmark

```bash
# Sequential benchmark
python optimize_admin.py benchmark --iterations 20

# Concurrent benchmark
python optimize_admin.py benchmark --concurrent --concurrency 10

# Output
/api/san_pham/    avg: 45.23ms    success: 100%
/api/banner/      avg: 12.45ms    success: 100%
/api/thu_vien/    avg: 89.12ms    success: 100%
```

### Cache Management

```bash
# Xem cache stats
python optimize_admin.py cache-stats

# Clear cache
python optimize_admin.py cache-clear
python optimize_admin.py cache-clear --pattern products

# Warm up cache
python optimize_admin.py cache-warmup
```

### Full Report

```bash
python optimize_admin.py report
# T·∫°o file: monitoring_report_20240115_143022.json
```

---

## üéõÔ∏è CONFIGURATION TUNING

### Uvicorn Settings (Production)

```bash
uvicorn ung_dung.chinh:ung_dung \
    --host 0.0.0.0 \
    --port 8000 \
    --workers 4 \
    --loop uvloop \
    --http httptools \
    --limit-concurrency 100 \
    --timeout-keep-alive 30
```

### Gunicorn Settings (Alternative)

```bash
gunicorn ung_dung.chinh:ung_dung \
    -w 4 \
    -k uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:8000 \
    --timeout 120 \
    --keep-alive 5
```

### Nginx (Reverse Proxy)

```nginx
upstream backend {
    server 127.0.0.1:8000;
    keepalive 32;
}

server {
    location /api/ {
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_buffering on;
        proxy_cache_valid 200 5m;
    }
}
```

---

## üìà Performance Checklist

### Backend

- [ ] Database indexes ƒë√£ ƒë∆∞·ª£c t·∫°o
- [ ] Connection pooling ƒë√£ c·∫•u h√¨nh
- [ ] GZip compression enabled
- [ ] Cache headers ƒë∆∞·ª£c set
- [ ] Slow query logging enabled
- [ ] Response time monitoring

### Admin Panel

- [ ] `@st.cache_data` cho API calls
- [ ] `@st.cache_resource` cho HTTP session
- [ ] Pagination cho lists l·ªõn
- [ ] Lazy loading cho images
- [ ] Parallel API requests
- [ ] Session state optimization

### Infrastructure

- [ ] Redis cache (production)
- [ ] Multiple workers (uvicorn/gunicorn)
- [ ] Nginx reverse proxy
- [ ] CDN cho static files
- [ ] Database connection limits

---

## üêõ Troubleshooting

### Slow Responses

1. Check database indexes: `EXPLAIN ANALYZE <query>`
2. Check cache hit rate: `/api/cache/stats`
3. Check slow query log
4. Profile v·ªõi `cProfile`

### Memory Issues

1. Check connection pool: `/api/health/detailed`
2. Reduce `pool_size` n·∫øu c·∫ßn
3. Enable `expire_on_commit=False`

### Cache Issues

1. Clear cache: `python optimize_admin.py cache-clear`
2. Check Redis connection
3. Verify cache TTL settings

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

- [FastAPI Performance](https://fastapi.tiangolo.com/deployment/concepts/)
- [SQLAlchemy Connection Pooling](https://docs.sqlalchemy.org/en/20/core/pooling.html)
- [Streamlit Caching](https://docs.streamlit.io/library/advanced-features/caching)
- [Redis Documentation](https://redis.io/documentation)

---

## ‚úÖ K·∫øt Lu·∫≠n

√Åp d·ª•ng c√°c t·ªëi ∆∞u h√≥a n√†y s·∫Ω gi√∫p:

| Metric | Before | After |
|--------|--------|-------|
| API Response Time | 500ms - 2s | 50ms - 200ms |
| Page Load (Admin) | 3-5s | 1-2s |
| Concurrent Users | 10-20 | 50-100 |
| Memory Usage | High | Optimized |
| Database Queries | N+1 | Optimized |

**L∆∞u √Ω**: Lu√¥n test tr√™n staging tr∆∞·ªõc khi deploy production!