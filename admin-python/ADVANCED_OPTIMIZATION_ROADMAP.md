# üöÄ Advanced Optimization Roadmap - IVIE Wedding Admin

Roadmap ƒë·ªÉ t·ªëi ∆∞u h√≥a th√™m 30-50% hi·ªáu nƒÉng sau khi ƒë√£ ƒë·∫°t ƒë∆∞·ª£c 70% c·∫£i thi·ªán ban ƒë·∫ßu.

---

## üìä Hi·ªán tr·∫°ng & M·ª•c ti√™u

### ‚úÖ ƒê√£ ƒë·∫°t ƒë∆∞·ª£c (v2.0)
- ‚ö° Startup: 8-12s ‚Üí 2-3s (‚Üì 70%)
- üíæ Memory: 250MB ‚Üí 100MB (‚Üì 60%)
- üñºÔ∏è Upload: 10-15s ‚Üí 2-3s (‚Üì 80%)
- üì¶ Lazy loading + Code splitting
- üóÑÔ∏è Smart caching (TTL-based)

### üéØ M·ª•c ti√™u ti·∫øp theo (v2.5 - v3.0)
- ‚ö° Startup: 2-3s ‚Üí 1-2s (th√™m 50%)
- üíæ Memory: 100MB ‚Üí 70MB (th√™m 30%)
- üåê Network: Gi·∫£m 50% requests
- üé® UI: 60fps constant
- üìä Real-time updates

---

## üéØ Priority Matrix

| Priority | Optimization | Impact | Effort | Timeline |
|----------|-------------|---------|--------|----------|
| **P0** üî• | CDN for images | High | Low | 1 day |
| **P0** üî• | Redis caching | High | Medium | 2 days |
| **P0** üî• | WebSocket real-time | High | Medium | 3 days |
| **P1** ‚≠ê | Virtual scrolling | Medium | Medium | 2 days |
| **P1** ‚≠ê | Service Worker PWA | Medium | Medium | 3 days |
| **P1** ‚≠ê | Query optimization | Medium | Low | 1 day |
| **P2** üí° | GraphQL API | High | High | 1 week |
| **P2** üí° | Advanced compression | Low | Low | 1 day |
| **P3** üé® | UI animations | Low | Low | 2 days |

---

## üî• PHASE 1: Quick Wins (1 tu·∫ßn)

### 1.1 CDN cho Images & Static Assets ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Gi·∫£m 60-80% th·ªùi gian load ·∫£nh

**Implementation:**

#### Option A: Cloudflare (Free)
```python
# modules/cdn_client.py
import os

CDN_URL = os.getenv("CDN_URL", "https://cdn.your-domain.com")

def get_cdn_url(path: str) -> str:
    """Convert local path to CDN URL"""
    if path.startswith("http"):
        return path
    return f"{CDN_URL}{path}"

# Usage
image_url = get_cdn_url("/uploads/product.jpg")
```

**Setup:**
1. Sign up Cloudflare (free)
2. Add domain
3. Enable CDN
4. Update image URLs

**Expected Result:**
- Load time: 3s ‚Üí 0.5s (‚Üì 83%)
- Bandwidth saved: 70%

---

#### Option B: Cloudinary (Free tier: 25GB)
```python
# modules/image_cdn.py
from cloudinary import uploader, CloudinaryImage
import cloudinary

cloudinary.config(
    cloud_name = os.getenv("CLOUDINARY_NAME"),
    api_key = os.getenv("CLOUDINARY_KEY"),
    api_secret = os.getenv("CLOUDINARY_SECRET")
)

def upload_to_cdn(file) -> str:
    """Upload v√† return CDN URL v·ªõi auto optimization"""
    result = uploader.upload(
        file,
        transformation=[
            {'width': 1000, 'crop': 'limit'},
            {'quality': 'auto'},
            {'fetch_format': 'auto'}  # WebP cho browser support
        ]
    )
    return result['secure_url']

def get_optimized_url(public_id: str, width: int = 400) -> str:
    """Get URL v·ªõi size c·ª• th·ªÉ (responsive images)"""
    return CloudinaryImage(public_id).build_url(
        width=width,
        crop='fill',
        quality='auto',
        fetch_format='auto'
    )
```

**Benefits:**
- ‚úÖ Auto WebP conversion
- ‚úÖ Responsive images
- ‚úÖ Global CDN
- ‚úÖ Free tier 25GB

---

### 1.2 Redis Caching Layer ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Gi·∫£m 70-90% API calls

**Architecture:**
```
Streamlit ‚Üí Redis Cache ‚Üí Backend API ‚Üí Database
            ‚Üì hit (90%)
            ‚Üì miss (10%) ‚Üí fetch & cache
```

**Implementation:**

```python
# modules/redis_cache.py
import redis
import json
import os
from typing import Optional, Any

# Connect to Redis (Render provides free Redis addon)
redis_client = redis.from_url(
    os.getenv("REDIS_URL", "redis://localhost:6379"),
    decode_responses=True
)

def cache_get(key: str) -> Optional[Any]:
    """Get from Redis cache"""
    try:
        data = redis_client.get(key)
        if data:
            return json.loads(data)
        return None
    except Exception as e:
        print(f"Redis get error: {e}")
        return None

def cache_set(key: str, value: Any, ttl: int = 300) -> bool:
    """Set to Redis cache with TTL"""
    try:
        redis_client.setex(
            key,
            ttl,
            json.dumps(value)
        )
        return True
    except Exception as e:
        print(f"Redis set error: {e}")
        return False

def cache_invalidate(pattern: str) -> None:
    """Invalidate cache by pattern"""
    try:
        keys = redis_client.keys(pattern)
        if keys:
            redis_client.delete(*keys)
    except Exception as e:
        print(f"Redis invalidate error: {e}")

# Enhanced API client with Redis
def fetch_api_data_redis(endpoint: str) -> Optional[Dict]:
    """Fetch with Redis caching"""
    cache_key = f"api:{endpoint}"
    
    # Try Redis first
    cached = cache_get(cache_key)
    if cached:
        return cached
    
    # Fetch from API
    data = fetch_api_data(endpoint)
    if data:
        # Cache for 5 minutes
        cache_set(cache_key, data, ttl=300)
    
    return data
```

**Setup on Render:**
```bash
# Add Redis addon (free tier available)
1. Render Dashboard ‚Üí Add-ons
2. Add "Redis" (free: 25MB)
3. Get REDIS_URL from environment
4. Use in code
```

**Expected Result:**
- API calls: -90%
- Response time: 100ms ‚Üí 5ms (‚Üì 95%)
- Backend load: -80%

---

### 1.3 Virtual Scrolling for Large Lists ‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Render 1000+ items without lag

**Current Problem:**
```python
# Hi·ªán t·∫°i: Render ALL items
for product in products:  # 1000 items
    st.write(product)  # Lag!
```

**Solution: Virtual Scrolling**
```python
# modules/virtual_scroll.py
import streamlit as st
from typing import List, Callable

def virtual_scroll(
    items: List,
    render_item: Callable,
    items_per_page: int = 50,
    container_height: int = 600
):
    """
    Virtual scrolling - ch·ªâ render items hi·ªÉn th·ªã
    
    Args:
        items: List of items to display
        render_item: Function to render each item
        items_per_page: Items per virtual page
        container_height: Container height in px
    """
    total_items = len(items)
    total_pages = -(-total_items // items_per_page)  # Ceiling
    
    # Pagination controls
    col1, col2, col3 = st.columns([2, 3, 2])
    with col1:
        page = st.number_input(
            "Page",
            min_value=1,
            max_value=total_pages,
            value=st.session_state.get("vscroll_page", 1),
            key="vscroll_page_input"
        )
    
    with col2:
        st.markdown(f"**{total_items}** items total")
    
    with col3:
        items_per_page = st.selectbox(
            "Items/page",
            [20, 50, 100],
            index=1,
            key="vscroll_items"
        )
    
    # Calculate range
    start_idx = (page - 1) * items_per_page
    end_idx = min(start_idx + items_per_page, total_items)
    
    # Render only visible items
    visible_items = items[start_idx:end_idx]
    
    # Container with fixed height
    with st.container():
        for idx, item in enumerate(visible_items):
            render_item(item, start_idx + idx)

# Usage
def render_product(product, index):
    with st.expander(f"{index+1}. {product['name']}"):
        st.write(product)

virtual_scroll(
    items=products,
    render_item=render_product,
    items_per_page=50
)
```

**Expected Result:**
- Render time: 5s ‚Üí 0.3s (for 1000 items)
- Smooth scrolling
- Lower memory usage

---

### 1.4 Debouncing for Search ‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Gi·∫£m 80% unnecessary API calls

**Implementation:**
```python
# modules/debounce.py
import time
import streamlit as st
from typing import Callable, Any

def debounced_input(
    label: str,
    key: str,
    delay: float = 0.5,
    on_change: Callable = None,
    **kwargs
) -> str:
    """
    Input v·ªõi debouncing - ch·ªâ trigger sau khi user ng·ª´ng g√µ
    
    Args:
        label: Input label
        key: Unique key
        delay: Delay in seconds
        on_change: Callback function
    """
    # Session state for debouncing
    debounce_key = f"{key}_debounce"
    last_change_key = f"{key}_last_change"
    
    # Initialize
    if debounce_key not in st.session_state:
        st.session_state[debounce_key] = ""
    if last_change_key not in st.session_state:
        st.session_state[last_change_key] = time.time()
    
    # Get current input
    current_value = st.text_input(label, key=key, **kwargs)
    
    # Check if changed
    if current_value != st.session_state[debounce_key]:
        st.session_state[last_change_key] = time.time()
        st.session_state[debounce_key] = current_value
    
    # Check if debounce period passed
    time_since_change = time.time() - st.session_state[last_change_key]
    
    if time_since_change >= delay:
        # Trigger callback
        if on_change and current_value:
            on_change(current_value)
        return current_value
    
    return st.session_state.get(f"{key}_confirmed", "")

# Usage
def search_products(query):
    st.session_state["search_results"] = call_api(
        "GET",
        f"/api/san_pham/search?q={query}"
    )

search_query = debounced_input(
    "T√¨m ki·∫øm s·∫£n ph·∫©m",
    key="product_search",
    delay=0.8,  # Wait 0.8s after user stops typing
    on_change=search_products
)
```

**Expected Result:**
- API calls: 10/second ‚Üí 1/second (‚Üì 90%)
- Server load: -90%
- Better UX

---

## ‚≠ê PHASE 2: Major Improvements (2-3 tu·∫ßn)

### 2.1 WebSocket Real-time Updates ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Real-time collaboration + instant updates

**Architecture:**
```
Admin 1 ‚îÄ‚îÄ‚îê
Admin 2 ‚îÄ‚îÄ‚îº‚îÄ‚îÄ> WebSocket Server ‚îÄ‚îÄ> Database
Admin 3 ‚îÄ‚îÄ‚îò         ‚îÇ
                    ‚îî‚îÄ‚îÄ> Broadcast updates
```

**Implementation:**

#### Backend: FastAPI WebSocket
```python
# backend/websocket_server.py
from fastapi import WebSocket, WebSocketDisconnect
from typing import List

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
    
    async def broadcast(self, message: dict):
        """Broadcast to all connected clients"""
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except:
                pass

manager = ConnectionManager()

@app.websocket("/ws/admin")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_json()
            # Process and broadcast
            await manager.broadcast({
                "type": "update",
                "data": data
            })
    except WebSocketDisconnect:
        manager.disconnect(websocket)

# Trigger broadcasts on data changes
@app.post("/api/don_hang/")
async def create_order(order: Order):
    # Create order
    new_order = await create_order_in_db(order)
    
    # Broadcast to all admins
    await manager.broadcast({
        "type": "new_order",
        "data": new_order
    })
    
    return new_order
```

#### Frontend: Streamlit WebSocket Client
```python
# modules/websocket_client.py
import asyncio
import websockets
import json
import streamlit as st
from threading import Thread

WS_URL = os.getenv("WS_URL", "ws://localhost:8000/ws/admin")

class WebSocketClient:
    def __init__(self):
        self.ws = None
        self.running = False
    
    async def connect(self):
        """Connect to WebSocket server"""
        self.ws = await websockets.connect(WS_URL)
        self.running = True
        
        while self.running:
            try:
                message = await self.ws.recv()
                data = json.loads(message)
                self.handle_message(data)
            except:
                break
    
    def handle_message(self, data):
        """Handle incoming message"""
        msg_type = data.get("type")
        
        if msg_type == "new_order":
            # Update session state
            if "orders" in st.session_state:
                st.session_state["orders"].insert(0, data["data"])
            # Trigger rerun to update UI
            st.rerun()
        
        elif msg_type == "update_order":
            # Update existing order
            if "orders" in st.session_state:
                for i, order in enumerate(st.session_state["orders"]):
                    if order["id"] == data["data"]["id"]:
                        st.session_state["orders"][i] = data["data"]
                        break
            st.rerun()
    
    def start(self):
        """Start WebSocket in background thread"""
        thread = Thread(target=self._run)
        thread.daemon = True
        thread.start()
    
    def _run(self):
        asyncio.run(self.connect())

# Initialize WebSocket
if "ws_client" not in st.session_state:
    st.session_state.ws_client = WebSocketClient()
    st.session_state.ws_client.start()
```

**Expected Result:**
- ‚úÖ Real-time order notifications
- ‚úÖ Multi-admin collaboration
- ‚úÖ No need to refresh
- ‚úÖ Instant updates

---

### 2.2 Progressive Web App (PWA) ‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Offline support + faster loading

**Implementation:**

#### Service Worker
```javascript
// static/service-worker.js
const CACHE_NAME = 'ivie-admin-v1';
const urlsToCache = [
  '/',
  '/static/css/style.css',
  '/static/js/app.js',
  '/static/images/logo.png'
];

// Install - cache static assets
self.addEventListener('install', event => {
  event.waitUntil(
    caches.open(CACHE_NAME)
      .then(cache => cache.addAll(urlsToCache))
  );
});

// Fetch - serve from cache, fallback to network
self.addEventListener('fetch', event => {
  event.respondWith(
    caches.match(event.request)
      .then(response => {
        // Cache hit
        if (response) {
          return response;
        }
        
        // Clone request
        const fetchRequest = event.request.clone();
        
        return fetch(fetchRequest).then(response => {
          // Check valid response
          if (!response || response.status !== 200) {
            return response;
          }
          
          // Clone response
          const responseToCache = response.clone();
          
          caches.open(CACHE_NAME)
            .then(cache => {
              cache.put(event.request, responseToCache);
            });
          
          return response;
        });
      })
  );
});
```

#### Manifest
```json
// static/manifest.json
{
  "name": "IVIE Wedding Admin",
  "short_name": "IVIE Admin",
  "description": "Admin dashboard for IVIE Wedding Studio",
  "start_url": "/",
  "display": "standalone",
  "background_color": "#0a0a0a",
  "theme_color": "#ffffff",
  "icons": [
    {
      "src": "/static/icons/icon-192.png",
      "sizes": "192x192",
      "type": "image/png"
    },
    {
      "src": "/static/icons/icon-512.png",
      "sizes": "512x512",
      "type": "image/png"
    }
  ]
}
```

#### Register in Streamlit
```python
# Add to quan_tri_optimized_v2.py
st.markdown("""
<link rel="manifest" href="/static/manifest.json">
<script>
if ('serviceWorker' in navigator) {
  navigator.serviceWorker.register('/static/service-worker.js')
    .then(reg => console.log('SW registered', reg))
    .catch(err => console.log('SW error', err));
}
</script>
""", unsafe_allow_html=True)
```

**Expected Result:**
- ‚úÖ Offline support
- ‚úÖ Install as app
- ‚úÖ Faster subsequent loads
- ‚úÖ Push notifications

---

### 2.3 Database Query Optimization ‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Gi·∫£m 50-70% query time

**Current Issues:**
- N+1 query problem
- No indexes
- Large data fetches

**Solutions:**

#### Backend: Add Indexes
```sql
-- Add indexes for frequently queried columns
CREATE INDEX idx_products_category ON products(category);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_orders_date ON orders(created_at DESC);
CREATE INDEX idx_contacts_status ON contacts(status);

-- Composite indexes for complex queries
CREATE INDEX idx_orders_status_date ON orders(status, created_at DESC);
CREATE INDEX idx_products_category_price ON products(category, price);
```

#### Backend: Use SELECT specific columns
```python
# ‚ùå Bad: Select all
orders = db.query(Order).all()

# ‚úÖ Good: Select only needed columns
orders = db.query(
    Order.id,
    Order.customer_name,
    Order.total,
    Order.status
).all()
```

#### Backend: Pagination at DB level
```python
# ‚ùå Bad: Fetch all, paginate in memory
all_orders = db.query(Order).all()
page_orders = all_orders[0:20]  # Fetch 1000, use 20!

# ‚úÖ Good: Paginate at DB
page_orders = db.query(Order)\
    .order_by(Order.created_at.desc())\
    .limit(20)\
    .offset(0)\
    .all()
```

#### Backend: Eager loading for relations
```python
# ‚ùå Bad: N+1 query
orders = db.query(Order).all()
for order in orders:
    items = order.items  # Extra query for each order!

# ‚úÖ Good: Eager load
orders = db.query(Order)\
    .options(joinedload(Order.items))\
    .all()
```

**Expected Result:**
- Query time: 500ms ‚Üí 50ms (‚Üì 90%)
- Database load: -70%
- Scalability improved

---

## üí° PHASE 3: Advanced Features (1 th√°ng)

### 3.1 GraphQL API Layer ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** Gi·∫£m 60% over-fetching, flexible queries

**Why GraphQL?**
- ‚úÖ Fetch exactly what you need
- ‚úÖ One request for multiple resources
- ‚úÖ Strongly typed
- ‚úÖ Real-time subscriptions

**Implementation:**

#### Backend: Add GraphQL
```python
# backend/graphql_schema.py
import strawberry
from typing import List, Optional

@strawberry.type
class Product:
    id: int
    name: str
    price: float
    category: str
    image_url: Optional[str]

@strawberry.type
class Order:
    id: int
    customer_name: str
    total: float
    status: str
    items: List[Product]

@strawberry.type
class Query:
    @strawberry.field
    def products(
        self,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Product]:
        # Fetch products
        query = db.query(ProductModel)
        if category:
            query = query.filter_by(category=category)
        return query.limit(limit).all()
    
    @strawberry.field
    def order(self, id: int) -> Optional[Order]:
        return db.query(OrderModel).get(id)
    
    @strawberry.field
    def dashboard_stats(self) -> dict:
        return {
            "total_products": db.query(ProductModel).count(),
            "total_orders": db.query(OrderModel).count(),
            "revenue": db.query(func.sum(OrderModel.total)).scalar()
        }

@strawberry.type
class Mutation:
    @strawberry.mutation
    def create_product(self, name: str, price: float) -> Product:
        product = ProductModel(name=name, price=price)
        db.add(product)
        db.commit()
        return product

schema = strawberry.Schema(query=Query, mutation=Mutation)

# Add to FastAPI
from strawberry.fastapi import GraphQLRouter

graphql_app = GraphQLRouter(schema)
app.include_router(graphql_app, prefix="/graphql")
```

#### Frontend: GraphQL Client
```python
# modules/graphql_client.py
import requests

GRAPHQL_URL = f"{API_URL}/graphql"

def graphql_query(query: str, variables: dict = None):
    """Execute GraphQL query"""
    response = requests.post(
        GRAPHQL_URL,
        json={
            "query": query,
            "variables": variables or {}
        }
    )
    return response.json()

# Usage: Fetch exactly what you need
query = """
query GetDashboard {
    products(limit: 10) {
        id
        name
        price
    }
    dashboardStats {
        totalProducts
        totalOrders
        revenue
    }
}
"""

data = graphql_query(query)
products = data["data"]["products"]
stats = data["data"]["dashboardStats"]
```

**Expected Result:**
- Data transfer: -60%
- API calls: -50%
- Flexibility: +100%

---

### 3.2 Advanced Image Optimization ‚≠ê‚≠ê‚≠ê‚≠ê

**Impact:** 90% smaller images, faster load

**Techniques:**

#### 1. WebP + AVIF Format
```python
# modules/image_optimizer.py
from PIL import Image
import io

def optimize_image_advanced(file, format="webp"):
    """
    Advanced image optimization
    - WebP: 30% smaller than JPEG
    - AVIF: 50% smaller than JPEG
    """
    img = Image.open(file)
    
    # Resize
    max_size = (1000, 1000)
    img.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    # Convert to RGB
    if img.mode in ("RGBA", "P"):
        img = img.convert("RGB")
    
    # Save as WebP or AVIF
    buffer = io.BytesIO()
    
    if format == "webp":
        img.save(buffer, format="WEBP", quality=85, method=6)
    elif format == "avif":
        # Requires pillow-avif-plugin
        img.save(buffer, format="AVIF", quality=80)
    else:
        img.save(buffer, format="JPEG", quality=80, optimize=True)
    
    buffer.seek(0)
    return buffer

# Usage with fallback
def get_optimized_image_url(path: str) -> str:
    """Return WebP URL with JPEG fallback"""
    webp_url = path.replace(".jpg", ".webp")
    return f"""
    <picture>
        <source srcset="{webp_url}" type="image/webp">
        <img src="{path}" alt="Image" loading="lazy">
    </picture>
    """
```

#### 2. Lazy Loading + Blur Placeholder
```python
def lazy_image(url: str, alt: str = ""):
    """Image with blur placeholder"""
    return f"""
    <img 
        src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 400 300'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='20'/%3E%3C/filter%3E%3Cimage filter='url(%23b)' x='0' y='0' height='100%25' width='100%25' href='{url}'/%3E%3C/svg%3E"
        data-src="{url}"
        alt="{alt}"
        loading="lazy"
        class="lazy-image"
        style="width:100%; height:auto;"
    >
    <script>
    document.addEventListener('DOMContentLoaded', function() {{
        const lazyImages = document.querySelectorAll('.lazy-image');
        const imageObserver = new IntersectionObserver((entries) => {{
            entries.forEach(entry => {{
                if (entry.isIntersecting) {{
                    const img = entry.target;
                    img.src = img.dataset.src;
                    imageObserver.unobserve(img);
                }}
            }});
        }});
        lazyImages.forEach(img => imageObserver.observe(img));
    }});
    </script>
    """
```

#### 3. Responsive Images
```python
def responsive_image(base_url: str):
    """Generate responsive image sizes"""
    return f"""
    <img 
        srcset="
            {base_url}?w=320 320w,
            {base_url}?w=640 640w,
            {base_url}?w=1024 1024w
        "
        sizes="(max-width: 320px) 280px,
               (max-width: 640px) 600px,
               1000px"
        src="{base_url}"
        alt="Responsive image"
    >
    """
```

**Expected Result:**
- Image size: -90%
- Load time: -85%
- Bandwidth: -80%

---

### 3.3 Server-Side Rendering (SSR) for Dashboard ‚≠ê‚≠ê‚≠ê

**Impact:** Instant first paint

**Implementation:**

```python
# Pre-render dashboard HTML on server
from jinja2 import Template

DASHBOARD_TEMPLATE = """
<!DOCTYPE html>
<html>
<head>
    <title>IVIE Admin Dashboard</title>
    <style>
        /* Critical CSS inline */
        body { margin: 0; font-family: sans-serif; }
        .metrics { display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; }
        .card { padding: 20px; background: #f5f5f5; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="metrics">
        <div class="card">
            <h3>S·∫£n ph·∫©m</h3>
            <p class="value">{{ total_products }}</p>
        </div>
        <div class="card">
            <h3>ƒê∆°n h√†ng</h3>
            <p class="value">{{ total_orders }}</p>
        </div>
        <div class="card">
            <h3>Doanh thu</h3>
            <p class="value">{{ revenue }}</p>
        </div>
        <div class="card">
            <h3>Li√™n h·ªá</h3>
            <p class="value">{{ total_contacts }}</p>
        </div>
    </div>
    <!-- Load Streamlit after initial render -->
    <script src="/_stcore/static/js/bootstrap.min.js"></script>
</body>
</html>
"""

@app.get("/admin/dashboard/ssr")
def get_dashboard_ssr():
    """Server-side rendered dashboard"""
    stats = get_dashboard_stats()
    
    template = Template(DASHBOARD_TEMPLATE)
    html = template.render(**stats)
    
    return HTMLResponse(content=html)
```

**Expected Result:**